{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hashing task\n",
    "For this task we have The first dataset which represents the \"pool\" of passwords and we have to find how many passwords of the second dataset are already present in the pool by implementing :\n",
    "- Hash function\n",
    "- Bloom Filter structur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math \n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password1=[]\n",
    "with open('../DS/passwords1.txt', 'r') as fh:\n",
    "    line=fh.readlines()\n",
    "    for i in range(len(line)):\n",
    "        password1.append(line[i].strip().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(password1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password2=[]\n",
    "with open('../DS/passwords2.txt', 'r') as f2:\n",
    "    line2=f2.readlines()\n",
    "    for i in range(len(line2)):\n",
    "        password2.append(line2[i].strip().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(password2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password2[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bloom filter \n",
    "\n",
    "#### At first we need to calculate :\n",
    "\n",
    "The error rate p =(1-e^-kn/m)^k\n",
    "\n",
    "The size of the filter m = n log P/(log2)^2\n",
    "\n",
    "The number of hash functions k = m/n log2\n",
    "\n",
    "n= the number of elements here we have 100,000,000 Passwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(password1)\n",
    "# As a start we will set error rate to 0.02 so we can calculate the m\n",
    "p=0.02\n",
    "m = round(-(n*math.log(p))/(math.log(2)**2)) #size of the bloom table\n",
    "bloomTable=['' for i in range(m)] #The bloom table which has the size of m filled with empty space\n",
    "k = round((m/n)*math.log(2)) #number of hash function \n",
    "\n",
    "print(\"filter size table = \", m ,'\\nNumber of hash functions needed = ', k ,\"\\nStarting Error rate = \", p, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different implementation \n",
    "def hash_func_1(password):\n",
    "    hashed_1 = 0\n",
    "    for i in range(len(password)):\n",
    "        hashed_1 += ord(password[i])\n",
    "    return (hashed_1%m) # first hashing function which take the ord of each char#devided by the table size\n",
    "\n",
    "\n",
    "def hash_func_2(password):\n",
    "    hashed_2 = 0\n",
    "    for i in range(len(password)):\n",
    "        hashed_2 += hashed_2+(ord(password[i]))**2 #Second hashing function which thake the ord of each char power 2\n",
    "    return (hashed_2%m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now we are Using  small fraction of the DS to test the code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x1=password1[:300]\n",
    "x2=password2[:300]\n",
    "n1=len(x1)\n",
    "# As a start we will set error rate to 0.02 so we can calculate the m\n",
    "p1=0.02\n",
    "m1 = round(-(n*math.log(p))/(math.log(2)**2))\n",
    "bloomTable1=['' for i in range(m1)]\n",
    "k1 = round((m/n)*math.log(2))\n",
    "print(\"filter size table = \", m1 ,'\\nNumber of hash functions needed = ', k1 ,\"\\nStarting Error rate = \", p1, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloom_filter(password1,password2):\n",
    "    \n",
    "    start=time.time()\n",
    "    \n",
    "    duplicates_counter = 0\n",
    "    not_duplicates=0\n",
    "    \n",
    "    for j in password1:\n",
    "        for u in j: #each list\n",
    "            pass1_1 = hash_func_1(u)\n",
    "            pass1_2 = hash_func_2(u)\n",
    "        #the fucntion will prouduce a number \n",
    "        #Fill the corresponding index in the bloom filter table with one \n",
    "        if bloomTable[pass1_1] != 1:\n",
    "            bloomTable[pass1_1] = 1       \n",
    "        if bloomTable[pass1_2] != 1:\n",
    "            bloomTable[pass1_2] = 1 \n",
    "         \n",
    "    # Now we work on the second data set \n",
    "    for i in password2:\n",
    "        for y in i:\n",
    "            pass2_1=hash_func_1(y)\n",
    "            pass2_2=hash_func_2(y)\n",
    "      \n",
    "        \n",
    "        if bloomTable[pass2_1] == 1 and bloomTable[pass2_2] == 1: # iF the bloom table index already filled with 1 meaning the hashed value of password1 occupied it\n",
    "            duplicates_counter += 1\n",
    "        else:\n",
    "            not_duplicates+=1\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print('Number of hash function used: ', k) # K form the bloom filter formula the nneeded hashing function ,but we used two hashing functions\n",
    "    #print('Number tot pass ', len(password1), len(password2))\n",
    "    print('Not_duplicates ',not_duplicates)\n",
    "    print('Number of duplicates detected: ', duplicates_counter )\n",
    "    print('Probability of false positives: ', p)\n",
    "    print('Execution time: ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_filter(password1,password2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Alphabetical Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives in input an array of integers and returns the sorted array and the order of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_sort(array):\n",
    "    aux_array = [0]*1000 \n",
    "    \n",
    "    # make auxilary array of size 1000, \n",
    "    # we suppose the ordinal are between 0 and 999, however it can be any range\n",
    "    \n",
    "    order = [0]*len(array) # fill list with zero len of the input\n",
    "    \n",
    "    \n",
    "    # calculate the frequencies , for every appearance of \n",
    "    for i in array: # the input\n",
    "        aux_array[i] += 1\n",
    "        \n",
    "        \n",
    "    # calculate the cumulative values of the frequencies\n",
    "    for i in range(1,len(aux_array)):\n",
    "        aux_array[i] += aux_array[i-1]\n",
    "    sorted_array = [None]*len(array)\n",
    "    \n",
    "    \n",
    "    # put tha values in array to sorted array on the right position and store the order\n",
    "    for j,i in enumerate(array):\n",
    "        order[aux_array[i]-1] = j\n",
    "        sorted_array[aux_array[i]-1] = i\n",
    "        aux_array[i] += -1\n",
    "    return sorted_array, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_sort([3,6,9,2,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting sort for letters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives in input an array of letters and returns them in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_sort_alpha(arr):\n",
    "    \n",
    "    count=[ 0 for i in range(256)] \n",
    "    #fill counter with zeros 256 index because we are using ord\n",
    "    alpha_=['' for _ in arr] \n",
    "    # to fill the ordered letters \n",
    "    \n",
    "    for a in arr:\n",
    "        count[ord(a)] += 1 \n",
    "        # count occurrence of each character \n",
    "        # and fill Corresponding ord index with letter counter\n",
    "        #print(count)\n",
    "    \n",
    "    for i in range(len(count)): \n",
    "        count[i] = count[i] + count[i-1] \n",
    "        #put each letter in its actual Position the count[i] \n",
    "        #counnt how many less or equal to the ord number \n",
    "        \n",
    "        #print(count)\n",
    "        \n",
    "    for i in range(len(arr)): \n",
    "        # for each index number from above minus 1 put the letter in the index number       \n",
    "        count[count[ord(arr[i])]-1] = arr[i] \n",
    "        count[ord(arr[i])] -= 1\n",
    "        #print(count)\n",
    "        \n",
    "    for i in range(len(arr)): \n",
    "        alpha_[i] = count[i] \n",
    "        #print(count[i] )\n",
    "    return (print(alpha_ , end=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counting_sort_alpha(['z','y','x','w','v','u','t','s','r','q','p','o','n','m','l','k','i','h','g','f','e','d','c','b','a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running time for Counting Sort for letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theoretical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counting sort alpha is basically 3 for-loops. \n",
    "\n",
    "The first and third loops look at the entire array of letters and positions them in a certain position. \n",
    "\n",
    "The second loop is only concerned with putting each letter in its actual position the count[i]. \n",
    "\n",
    "Then first and third we will have a complexity of O (n), \n",
    "\n",
    "for the second O (k). \n",
    "\n",
    "Adding these values ​​we will have that the complexity will be O (n + k).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count_sort():    \n",
    "    time_tot = list()\n",
    "    # change m from 10 to 100000 with steps of 10000\n",
    "    for m in range(10,100000,10000):\n",
    "        time_ = list()\n",
    "        let = np.random.randint(ord('A'), ord('z')+1, m)\n",
    "        start = time.time()\n",
    "        sorted_words_list = counting_sort(let) # same thing of counting_sort_alpha\n",
    "        end_time = time.time()\n",
    "        time_.append(end_time - start)\n",
    "        time_tot.append(sum(time_))\n",
    "   #PLOT\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    plt.plot(range(10,100000,10000),time_tot)\n",
    "    plt.xlabel('Letter lenght')\n",
    "    plt.ylabel('Running time (secs)')\n",
    "    plt.title('Running time for counting sort')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe the complexity is linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabetical sort based on counting sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to sort an array of strings alphabetically.\n",
    "\n",
    "What we will do first is to create a matrix containing for each position a value that corresponds to a letter.\n",
    "\n",
    "\n",
    "Then we will order this matrix starting from the first column to the last one.\n",
    "\n",
    "We must be careful NOT to reorder the columns already ordered because in that case we could remix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert all letter of our words in number and store them in a matrix to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the letters in the words to numbers\n",
    "def create_matrix(words):  \n",
    "    m = max(map(len, words)) #creat array size max number of words == pos of each letter index\n",
    "    n = len(words)\n",
    "    \n",
    "    arrays = np.zeros((n, m+1), dtype=int) #the matrix size row=words size , col word size\n",
    "    arrays[:,-1] = range(n)\n",
    "    for i,word in enumerate(words):\n",
    "        arrays[i,range(len(word))] = list(map(ord, word.lower()))\n",
    "        \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_matrix(\"sapienza uni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an ordered array, if there is 2 or more equal value, merge them in a 'group'\n",
    "\n",
    "letter was mentioned twice or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group(array, index):\n",
    "    \n",
    "    problem_list = list()\n",
    "    problem = [index[0]]\n",
    "    for i in range(1,len(array)):\n",
    "        if array[i] == array[i-1]:\n",
    "            problem.append(index[i])\n",
    "        else:\n",
    "            problem_list.append(problem)\n",
    "            problem = [index[i]]\n",
    "    problem_list.append(problem)\n",
    "    return problem_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_group([0, 1, 1, 3, 6, 9], [5, 4, 3, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to see how many equal values there are for each 'column'. \n",
    "\n",
    "If it is one it means that the value is in the correct position,\n",
    "\n",
    "if it is not so, then we apply the previous function to those 'column' and we'll order them.\n",
    "\n",
    "\n",
    "This is a recursive function becouse if there are further equal values after those found then I call the function and I also order and concaten them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_eq_col(arrays, i):\n",
    "    \n",
    "    if arrays.shape[0] == 1:\n",
    "        return arrays\n",
    "    else:\n",
    "        # reorder equal columns (splitted by 'group') \n",
    "        sorted_array, order = counting_sort(arrays[:,i])\n",
    "        arrays = arrays[order,:]\n",
    "        \n",
    "        if (i+1) < arrays.shape[1] :\n",
    "            list_groups = make_group(sorted_array,list(range(arrays.shape[0])))\n",
    "            list_array = list()\n",
    "            for problem in list_groups:\n",
    "                list_array.append(sort_eq_col(arrays[problem,:], i+1))\n",
    "            arrays = np.concatenate(list_array, axis = 0)\n",
    "        return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally we have our function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort words in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_counting_sort():\n",
    "    words=list(map(str,input(\"Enter words: \").split()))\n",
    "    arrays = create_matrix(words) \n",
    "    #creat matrix of the word 1st col will be ord , 2nd col is pos index of letters\n",
    "   \n",
    "    sorted_array = sort_eq_col(arrays, 0) #to check similar letters\n",
    "    \n",
    "    order = list(map(int, sorted_array[:,-1]))\n",
    "    return([words[i] for i in order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words_list = alpha_counting_sort()\n",
    "print(sorted_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Time for alphabetical sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theoretical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm was implemented through a recursive function. In particular, putting the words 'one above the other', when there are two identical letters on the same 'column', a group of letters to be ordered is created and the function is called.\n",
    "The worst case occurs if the words are all the same so we have to call the function L times, ie the word length.\n",
    "So, since the counting sort algorithm has a running time of O (k + n), we have to repeat this L times.\n",
    "So for this algorithm the complexity will be O(Lk + Ln)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Adjustment to the algorithm that first took the words that the user wrote, now the words are already present in an external array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_counting_sortC(words):\n",
    "    arrays = create_matrix(words)\n",
    "    sorted_array = sort_eq_col(arrays, 0)\n",
    "    order = list(map(int, sorted_array[:,-1]))\n",
    "    return([words[i] for i in order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_vec = np.vectorize(chr)\n",
    "def plot_alpha_sort():\n",
    "    # we need to fix the number of words\n",
    "    m = 50\n",
    "    time_tot = list()\n",
    "    # change n from 10 to 10000 with steps of 1000\n",
    "    for n in range(10,10000,1000):\n",
    "        time_ = list()\n",
    "        \n",
    "        ordinals_list = np.random.randint(ord('A'), ord('z')+1, (m,n))\n",
    "        chr_lists = chr_vec(ordinals_list)\n",
    "        words_list = list()\n",
    "        # convert ordinals to words\n",
    "        for i in range(chr_lists.shape[0]):\n",
    "            words_list.append(\"\".join(chr_lists[i,:]))\n",
    "        start_time = time.time()\n",
    "        sorted_words_list = alpha_counting_sortC(words_list)\n",
    "        end_time = time.time()\n",
    "        time_.append(end_time - start_time)\n",
    "        time_tot.append(sum(time_))\n",
    "   \n",
    "    # PLOT\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    plt.plot(range(10,100000,10000),time_tot)\n",
    "    plt.xlabel('Number of words')\n",
    "    plt.ylabel('Running time (secs)')\n",
    "    plt.title('Running time for fixed word lenght')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alpha_sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of this task is based on the algorithm of group # 24, we thank them for the help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find similar wines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This k-means is implemented by reasoning in terms of products between matrices.\n",
    "\n",
    "Our goal is to create clusters, which will have deviance within (inside groups) and a deviance between (between groups).\n",
    "Therefore, we can minimize deviance within or maximize deviance between.\n",
    "We choose to minimize deviance within because we can set a threshold for which our objective function is satisfied, if it is satisfied it means that the position of the centroids varies little.\n",
    "\n",
    "The objective function will be:\n",
    "\\begin{equation*}\n",
    "minimize ||X-UX^{c}||^{2}\n",
    "\\end{equation*}\n",
    "\n",
    "Where:\n",
    "- X is our data matrix (NxJ)\n",
    "- U is our membership matrix (NxK) that defines where u_{ik} = 1 if the unit i belongs to the class k, u_{ik} = 0 otherwise.\n",
    "-  X^{c} is our centroid matrix (KxJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read and standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(genfromtxt(r'../DS/wine.data', delimiter=','))\n",
    "data = data.drop(data.columns[[0]], axis='columns')\n",
    "\n",
    "#### datacolumns\n",
    "data.columns = [\n",
    "    'Alcohol',\n",
    "    'Malic acid',\n",
    "    'Ash',\n",
    "    'Alcalinity_of_ash',\n",
    "    'Magnesium',\n",
    "    'Total_phenols',\n",
    "    'Flavanoids',\n",
    "    'Nonflavanoid_phenols',\n",
    "    'Proanthocyanins',\n",
    "    'Color_intensity',\n",
    "    'Hue',\n",
    "    'OD280/OD315_of_diluted_wines',\n",
    "    'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagonalize(su):\n",
    "    '''\n",
    "    Create a matrix with weights on the diagonal.\n",
    "\n",
    "    :param su: diagonal of a matrix\n",
    "    :return: diagonal matrix\n",
    "    '''\n",
    "\n",
    "    Uzero = []\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero.append([0] * len(su))\n",
    "\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero[j][j] = su[j]\n",
    "    Uzero = pd.DataFrame(Uzero)\n",
    "    return Uzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizeDataFrame(data):\n",
    "    u = pd.DataFrame([1]*len(data))\n",
    "    _u = u.transpose()\n",
    "    _dot1 = pd.DataFrame(np.dot(u, _u))\n",
    "    \n",
    "    mat = round(pd.DataFrame(np.dot(1/len(data), _dot1)), 4)\n",
    "    \n",
    "    #centrature matrix\n",
    "    Jc = np.identity(len(data)) - mat\n",
    "    dot_data = pd.DataFrame(np.dot(Jc, data))\n",
    "    dot_data2 = np.dot(dot_data.transpose(), dot_data)\n",
    "    s_data = round(pd.DataFrame(np.dot(1/len(data), dot_data2)), 4)\n",
    "\n",
    "    diagonal = np.array(np.diag(s_data))\n",
    "    d2 = diagonalize(diagonal)**0.5\n",
    "    d2_inv = pd.DataFrame(np.linalg.pinv(d2.values)) #pseudo inverse\n",
    "\n",
    "    dot1 = pd.DataFrame(np.dot(data, d2_inv))\n",
    "    stand = round(pd.DataFrame(np.dot(Jc, dot1)), 4)\n",
    "    return stand\n",
    "\n",
    " # standardize DataFrame\n",
    "dataS = standardizeDataFrame(data)\n",
    "\n",
    "print(dataS.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose number of cluster and create them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the number of clusters we use Cost (SSE).\n",
    "\n",
    "The formula measures how the clusters are homogeneous internally.\n",
    "\n",
    "You select the number of clusters that (in the graph that will be created) corresponds to the point where there is an 'elbow': \n",
    "\n",
    "in that point the SSE will tend not to decrease more quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can then calculate the K-Means by different number of clusters and see their Cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randPU(n, K):\n",
    "    '''\n",
    "    Membership of a unit in a cluster (initialization)\n",
    "\n",
    "\n",
    "    :param n: len(matrix)\n",
    "    :param K: number of cluster\n",
    "    :return: misleading matrix\n",
    "    '''\n",
    "    # all 0 matrix\n",
    "    Uzero = []\n",
    "    for k in range(0, n):\n",
    "        Uzero.append([0] * K)\n",
    "\n",
    "    # random matrix of appartenence\n",
    "    for row in range(0, n):\n",
    "        Uzero[row][randrange(K)] = 1\n",
    "\n",
    "    return Uzero\n",
    "\n",
    "\n",
    "def dwdb(data, U, Xm, K):\n",
    "    u = pd.DataFrame([1] * len(data))\n",
    "    _u = u.transpose()\n",
    "    _dot1 = pd.DataFrame(np.dot(u, _u))\n",
    "    mat = round(pd.DataFrame(np.dot(1 / len(data), _dot1)), 4)\n",
    "    # centrature matrix\n",
    "    Jc = pd.DataFrame(np.identity(len(data)) - mat)\n",
    "\n",
    "    data_c = round(pd.DataFrame(np.dot(Jc, data)), 4)\n",
    "    _Xm = round(pd.DataFrame(np.dot(pd.DataFrame(np.linalg.pinv(U.values)), data)), 4)\n",
    "\n",
    "    #WITHIN\n",
    "    p = data_c - np.dot(U, _Xm)\n",
    "    D_w = np.trace(np.dot(p.transpose(), p))\n",
    "\n",
    "    #BETWEEN\n",
    "    b = np.dot(U, _Xm)\n",
    "    D_b = np.trace(np.dot(b.transpose(), b))\n",
    "    \n",
    "   \n",
    "\n",
    "    return (D_b/(K-1))/(D_w/(len(data)-K))\n",
    "\n",
    "\n",
    "def diagSU(su):\n",
    "    '''\n",
    "    Diagonal matrix of sum_col calculate\n",
    "    \n",
    "    :param su: sum of U_0 columns\n",
    "    :return: diagonal matrix 1/sum_column\n",
    "    '''\n",
    "    Uzero = []\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero.append([0] * len(su))\n",
    "\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero[j][j] = 1 / su[j]\n",
    "\n",
    "    return Uzero\n",
    "\n",
    "def diagonalize(su):\n",
    "    '''\n",
    "\n",
    "    :param su: diagonal of a matrix\n",
    "    :return: diagonal matrix\n",
    "    '''\n",
    "\n",
    "    Uzero = []\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero.append([0] * len(su))\n",
    "\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero[j][j] = su[j]\n",
    "    Uzero = pd.DataFrame(Uzero)\n",
    "    return Uzero\n",
    "\n",
    "def mse(Xrow, Xmean0row1):\n",
    "    min_dif = 0\n",
    "    for r in range(0, len(Xrow)):\n",
    "\n",
    "        min_dif += (Xrow[r] - Xmean0row1[r])**2\n",
    "        \n",
    "    MSE = min_dif/len(Xrow)\n",
    "    return MSE\n",
    "\n",
    "def mse2(Xrow, Xmean0row1):\n",
    "    min_dif = 0\n",
    "    for r in range(0, len(Xrow)):\n",
    "        \n",
    "        min_dif += (Xrow[r] - Xmean0row1[r])**2\n",
    "        \n",
    "    MSE = min_dif/len(Xrow)\n",
    "    return MSE\n",
    "\n",
    "def costf(X, Xmean_ott, U):\n",
    "    cost = 0\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, len(U.iloc[0])):\n",
    "            if U.iloc[i, j] == 1:\n",
    "                cost += mse(X.iloc[i], Xmean_ott.iloc[j])\n",
    "    return cost            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, K, Rndstart):\n",
    "    '''\n",
    "\n",
    "    :param X: data Matrix\n",
    "    :param K: Number of cluster of the partition\n",
    "    :param Rndstart: number of random start\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    maxiter = 100\n",
    "    n = len(X)\n",
    "    j = len(X.iloc[0])\n",
    "    epsilon = 0.00001\n",
    "\n",
    "    # find the best solution in a fixed number of random start partitions\n",
    "    for loop in range(0, Rndstart):\n",
    "        \n",
    "        # initial partition U_0 is given\n",
    "        U_0 = pd.DataFrame(randPU(n, K))\n",
    "        \n",
    "        # column frequency = random cluster\n",
    "        sum_col = []\n",
    "        for r in range(0, K):\n",
    "            sum_col.append(sum(U_0[r]))\n",
    "        \n",
    "        # 1/su on diagonal of a NxN matrix\n",
    "        su_diag = diagSU(sum_col)\n",
    "\n",
    "        # given U, compute Xmean initial (centroids)\n",
    "        Ut = U_0.transpose()\n",
    "        dot1 = pd.DataFrame(np.dot(su_diag, Ut))\n",
    "\n",
    "        Xmean0 = round(pd.DataFrame(np.dot(dot1, X)), 4)\n",
    "        \n",
    "\n",
    "        U = []\n",
    "        for r in range(0, n):\n",
    "            U.append([0] * K)\n",
    "\n",
    "\n",
    "        for iter in range(1,maxiter):\n",
    "            #given Xmean, assign each units to the closest cluster\n",
    "            \n",
    "                    \n",
    "            \n",
    "            for r in range(0, n):\n",
    "                \n",
    "                min_dif = mse(X.iloc[r], Xmean0.iloc[0])\n",
    "                \n",
    "                posmin = 0\n",
    "                for j in range(1, K):\n",
    "                    dif = mse(X.iloc[r], Xmean0.iloc[j])\n",
    "                    if dif < min_dif:\n",
    "                        min_dif = dif\n",
    "                        posmin = j\n",
    "                U[r][posmin] = 1\n",
    "            \n",
    "            U = pd.DataFrame(U)\n",
    "            \n",
    "\n",
    "            # given a partition of units, so given U, \n",
    "            #compute Xmean uptaded (centroids)\n",
    "\n",
    "            # update sum_col\n",
    "            sum_col = []\n",
    "            for t in range(0, K):\n",
    "                sum_col.append(sum(U[t]))\n",
    "            \n",
    "            \n",
    "            ## RARE CASE (BUT POSSIBLE) #############################################################\n",
    "            #if there is some empty cluster we must split the cluster with max sum_col\n",
    "            while sum([sum_col[h] == 0 for h in range(0, len(sum_col))]) > 0: # some cluster is empty\n",
    "\n",
    "                p1 = min(sum_col)\n",
    "                p2 = max(sum_col)\n",
    "\n",
    "                # select min column (empty cluster)\n",
    "                for j in range(0, len(sum_col)):\n",
    "                    if p1 == sum_col[j]:\n",
    "                        c1 = j\n",
    "\n",
    "                # select max column (cluster) for split its points to empty cluster\n",
    "                for k in range(0, len(sum_col)):\n",
    "                    if p2 == sum_col[k]:\n",
    "                        c2 = k\n",
    "\n",
    "                # list of units in max column (cluster)\n",
    "                ind = []\n",
    "                for row in range(0, len(U)):\n",
    "                    if int(U.iloc[row, c2]) == 1:\n",
    "                        ind.append(row)\n",
    "\n",
    "                # split max cluster\n",
    "                ind2 = []\n",
    "                for row in range(0, p2//2):\n",
    "                    ind2.append(row)\n",
    "\n",
    "                for row in range(0, len(ind2)):\n",
    "                    U.iloc[row, c1] = 1\n",
    "                    U.iloc[row, c2] = 0\n",
    "\n",
    "                sum_col = []\n",
    "                for q in range(0, K):\n",
    "                    sum_col.append(sum(U[q]))\n",
    "            #################################################################################################\n",
    "            \n",
    "            # give U compute centroids\n",
    "            _U = U.transpose()\n",
    "            _dot1 = pd.DataFrame(np.dot(diagSU(sum_col), _U))\n",
    "            Xmean = round(pd.DataFrame(np.dot(dot1, X)), 4)\n",
    "            \n",
    "\n",
    "            #compute ojective function\n",
    "            BB = (np.dot(U, Xmean)) - X\n",
    "            f = round(np.trace(np.dot(BB.transpose(), BB)), 4)\n",
    "\n",
    "\n",
    "            #stopping rule\n",
    "            dif = 0\n",
    "            \n",
    "            for k in range(0, K):\n",
    "                dif += mse2(Xmean.iloc[k], Xmean0.iloc[k])\n",
    "                    \n",
    "            if dif > epsilon:\n",
    "                Xmean0 = Xmean\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if loop == 0:\n",
    "            U_ott = U\n",
    "            f_ott = f\n",
    "            Xmean_ott = Xmean\n",
    "\n",
    "        if f < f_ott:\n",
    "            \n",
    "            U_ott = U\n",
    "            f_ott = f\n",
    "            Xmean_ott = Xmean\n",
    "            \n",
    "\n",
    "    # calculate cost\n",
    "    cost = costf(X, Xmean_ott, U_ott)\n",
    "    print('Done')\n",
    "    return round(pd.DataFrame(U_ott), 4), f_ott, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally calculate cost for different K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = []\n",
    "for i in range(1, 6):\n",
    "    solutions.append(kmeans(dataS, i, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=[]\n",
    "for i in range(0, len(solutions)):\n",
    "    cost.append(solutions[i][2])\n",
    "\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost)\n",
    "plt.annotate('Optimal number of clusters',\n",
    "            xy=(2.2, cost[2]))\n",
    "plt.plot(2, cost[2], marker='o', color='r')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.xticks([0,1,2,3,4], [1,2,3,4,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the optimal number of clusters is 3 and we can recalculate the clusters more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = solutions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see each cluster of what unit is formed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterization(cluster, data):\n",
    "    c1 = []\n",
    "    c2 = []\n",
    "    c3 = []\n",
    "    for i in range(0, len(data)):\n",
    "        if cluster[0].iloc[i][0] == 1:\n",
    "            c1.append(data.iloc[i])\n",
    "        if cluster[0].iloc[i][1] == 1:\n",
    "            c2.append(data.iloc[i])\n",
    "        if cluster[0].iloc[i][2] == 1:\n",
    "            c3.append(data.iloc[i])\n",
    "\n",
    "    c1 = pd.DataFrame(c1)\n",
    "    c2 = pd.DataFrame(c2)\n",
    "    c3 = pd.DataFrame(c3)\n",
    "    return c1, c2, c3\n",
    "\n",
    "division = clusterization(cluster, data) \n",
    "#output: pos0=cluster1, pos1=cluster2, pos2=cluster3\n",
    "\n",
    "for i in range(0, len(division)):\n",
    "    print('Cluster', i+1 ,'\\n',division[i].head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how many units is formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(division)):\n",
    "    print('Cluster', i+1, 'has', len(division[i]), 'units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal cost is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. See for which variables the clusters were formed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which variables contributed most to cluster creation, we can calculate the F-measure for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_variables(X, U):\n",
    "    U_inv = pd.DataFrame(np.linalg.pinv(U.values))\n",
    "\n",
    "    fm = []\n",
    "    for var in range(0, len(X.iloc[0])):\n",
    "        z_vars = stats.zscore(X.iloc[:, var])\n",
    "        Xm = np.dot(U_inv, z_vars)\n",
    "        Db = np.dot(np.dot(Xm.transpose(), U.transpose()), np.dot(U, Xm))\n",
    "        Dw = np.dot((z_vars - (np.dot(U, Xm))).transpose(), (z_vars - np.dot(U, Xm)))\n",
    "        fm.append( (Db/(len(U.iloc[0]) - 1)) / (Dw/(len(X) - len(U.iloc[0]))))\n",
    "\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_measure_variables = f_variables(data, cluster[0])\n",
    "print(f_measure_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the variables with the highest F-measure are those corresponding to positions 5, 6, 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL PHENOLS\n",
    "sns.set(color_codes=True)\n",
    "plt.subplot(121)\n",
    "sns.distplot(data.iloc[:, 5], kde=False);\n",
    "plt.subplot(122)\n",
    "for i in range(0, len(division)):\n",
    "    sns.distplot(division[i].iloc[:, 5], kde=False, bins=10);\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Flavanoids\n",
    "plt.subplot(121)\n",
    "sns.distplot(data.iloc[:, 6], kde=False);\n",
    "plt.subplot(122)\n",
    "for i in range(0, len(division)):\n",
    "    sns.distplot(division[i].iloc[:, 6], kde=False, bins=10);\n",
    "plt.show()\n",
    "\n",
    "# OD280/OD315_of_diluted_wines\n",
    "plt.subplot(121)\n",
    "sns.distplot(data.iloc[:, 11], kde=False);\n",
    "plt.subplot(122)\n",
    "for i in range(0, len(division)):\n",
    "    sns.distplot(division[i].iloc[:, 11], kde=False, bins=10);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. K-means can go wrong!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is able to find the optimal solution in a few steps, but sometimes it can take the wrong path.\n",
    "\n",
    "The choice of the initial partition can affect the final partition. \n",
    "\n",
    "In other words, the algorithm can be trapped between local minimal.\n",
    "\n",
    "In order not to make this thing happen it is possible to initialize the algorithm in different ways that guarantee us (more or less) an optimal solution or close to it.\n",
    "\n",
    "We can initialize K-means with:\n",
    "\n",
    "- Random Start: \n",
    "\n",
    "the algorithm is repeated with different initial classifications chosen randomly and it is chosen between the final ones, that of minimum deviance (cost);\n",
    "\n",
    "- Rational Choice: \n",
    "maximum distance centroids.\n",
    "\n",
    "We pay attention to rational choice. If we reason on the contrary it means that if we put the centroids all in the central point of the units (or in any case very close to each other), the algorithm could reach a NOT optimal solution.\n",
    "\n",
    "So we can implement a new algorithm to see if our objective function is arbitrarily larger from the cost of the optimal solution, which in our case is about '145'.\n",
    "\n",
    "Attention: there is no need to perform a random start because the centroids are chosen by us and the value of the objective function will always be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We choose the same number of clusters as in point 3, which is 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then implement K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRONG INIZIALIZATION, this assures us that initially the centroids are all in the center.\n",
    "def randPU_wrong2(n, K):\n",
    "    # all 0 matrix\n",
    "    Uzero = []\n",
    "    for k in range(0, n):\n",
    "        Uzero.append([1] * K)\n",
    "\n",
    "    return Uzero\n",
    "\n",
    "# UTILS FUNCTIONS\n",
    "def mse(Xrow, Xmean0row1):\n",
    "    min_dif = 0\n",
    "    for r in range(0, len(Xrow)):\n",
    "\n",
    "        min_dif += (Xrow[r] - Xmean0row1[r])**2\n",
    "        \n",
    "    MSE = min_dif/len(Xrow)\n",
    "    return MSE\n",
    "\n",
    "def mse2(Xrow, Xmean0row1):\n",
    "    min_dif = 0\n",
    "    for r in range(0, len(Xrow)):\n",
    "        \n",
    "        min_dif += (Xrow[r] - Xmean0row1[r])**2\n",
    "        \n",
    "    MSE = min_dif/len(Xrow)\n",
    "    return MSE\n",
    "\n",
    "def costf(X, Xmean_ott, U):\n",
    "    cost = 0\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, len(U.iloc[0])):\n",
    "            if U.iloc[i, j] == 1:\n",
    "                cost += mse(X.iloc[i], Xmean_ott.iloc[j])\n",
    "    return cost            \n",
    "\n",
    "def diagSU(su):\n",
    "    '''\n",
    "\n",
    "    :param su: sum of U_0 columns\n",
    "    :return: diagonal matrix\n",
    "    '''\n",
    "    Uzero = []\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero.append([0] * len(su))\n",
    "\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero[j][j] = 1 / su[j]\n",
    "\n",
    "    return Uzero\n",
    "\n",
    "def diagonalize(su):\n",
    "    '''\n",
    "\n",
    "    :param su: diagonal of a matrix\n",
    "    :return: diagonal matrix\n",
    "    '''\n",
    "\n",
    "    Uzero = []\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero.append([0] * len(su))\n",
    "\n",
    "    for j in range(0, len(su)):\n",
    "        Uzero[j][j] = su[j]\n",
    "    Uzero = pd.DataFrame(Uzero)\n",
    "    return Uzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_wrong(X, K, Rndstart):\n",
    "\n",
    "    '''\n",
    "\n",
    "    :param X: data Matrix\n",
    "    :param K: Number of cluster of the partition\n",
    "    :param Rndstart: number of random start\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    maxiter = 100\n",
    "    n = len(X)\n",
    "    j = len(X.iloc[0])\n",
    "    epsilon = 0.00001\n",
    "\n",
    "    # find the best solution in a fixed number of random start partitions\n",
    "    for loop in range(0, Rndstart):\n",
    "        \n",
    "        # initial WRONG partition U_0 is given\n",
    "         \n",
    "        U_0 = pd.DataFrame(randPU_wrong2(n, K))\n",
    "        \n",
    "        # column frequency = random cluster\n",
    "        sum_col = []\n",
    "        for r in range(0, K):\n",
    "            sum_col.append(sum(U_0[r]))\n",
    "        \n",
    "        # 1/su on diagonal of a NxN matrix\n",
    "        su_diag = diagSU(sum_col)\n",
    "\n",
    "        # given U compute Xmean (centroids)\n",
    "        Ut = U_0.transpose()\n",
    "        dot1 = pd.DataFrame(np.dot(su_diag, Ut))\n",
    "\n",
    "        Xmean0 = round(pd.DataFrame(np.dot(dot1, X)), 4)\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for iter in range(1,maxiter):\n",
    "            #given Xmean = assign each units to the closest cluster\n",
    "            U = []\n",
    "            for r in range(0, n):\n",
    "                 U.append([0] * K)\n",
    "                    \n",
    "            \n",
    "            for r in range(0, n):\n",
    "                \n",
    "                min_dif = mse(X.iloc[r], Xmean0.iloc[0])\n",
    "                \n",
    "                posmin = 0\n",
    "                for j in range(1, K):\n",
    "                    \n",
    "                    dif = mse(X.iloc[r], Xmean0.iloc[j])\n",
    "                    if dif < min_dif:\n",
    "                        min_dif = dif\n",
    "                        posmin = j\n",
    "                U[r][posmin] = 1\n",
    "            \n",
    "            U = pd.DataFrame(U)\n",
    "            \n",
    "\n",
    "            # given a partition of units, so given U compute Xmean (centroids)\n",
    "\n",
    "            # update sum_col\n",
    "            sum_col = []\n",
    "            for t in range(0, K):\n",
    "                sum_col.append(sum(U[t]))\n",
    "            \n",
    "            \n",
    "            ## RARE CASE (BUT POSSIBLE) #############################################################\n",
    "            #if there is some empty cluster we must split the cluster with max sum_col\n",
    "            while sum([sum_col[h] == 0 for h in range(0, len(sum_col))]) > 0: # some cluster is empty\n",
    "\n",
    "                p1 = min(sum_col)\n",
    "                p2 = max(sum_col)\n",
    "\n",
    "                # select min column (empty cluster)\n",
    "                for j in range(0, len(sum_col)):\n",
    "                    if p1 == sum_col[j]:\n",
    "                        c1 = j\n",
    "\n",
    "                # select max column (cluster) for split its points to empty cluster\n",
    "                for k in range(0, len(sum_col)):\n",
    "                    if p2 == sum_col[k]:\n",
    "                        c2 = k\n",
    "\n",
    "                # list of units in max column (cluster)\n",
    "                ind = []\n",
    "                for row in range(0, len(U)):\n",
    "                    if int(U.iloc[row, c2]) == 1:\n",
    "                        ind.append(row)\n",
    "\n",
    "                # split max cluster\n",
    "                ind2 = []\n",
    "                for row in range(0, p2//2):\n",
    "                    ind2.append(row)\n",
    "\n",
    "                for row in range(0, len(ind2)):\n",
    "                    U.iloc[row, c1] = 1\n",
    "                    U.iloc[row, c2] = 0\n",
    "\n",
    "                sum_col = []\n",
    "                for q in range(0, K):\n",
    "                    sum_col.append(sum(U[q]))\n",
    "            #################################################################################################\n",
    "            \n",
    "            # give U compute centroids\n",
    "            _U = U.transpose()\n",
    "            _dot1 = pd.DataFrame(np.dot(diagSU(sum_col), _U))\n",
    "            Xmean = round(pd.DataFrame(np.dot(dot1, X)), 4)\n",
    "            \n",
    "\n",
    "            #compute ojective function\n",
    "            BB = (np.dot(U, Xmean)) - X\n",
    "            f = round(np.trace(np.dot(BB.transpose(), BB)), 4)\n",
    "\n",
    "\n",
    "            #stopping rule\n",
    "            dif = 0\n",
    "            \n",
    "            for k in range(0, K):\n",
    "                dif += mse2(Xmean.iloc[k], Xmean0.iloc[k])\n",
    "                    \n",
    "            if dif > epsilon:\n",
    "                Xmean0 = Xmean\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if loop == 0:\n",
    "            U_ott = U\n",
    "            f_ott = f\n",
    "            Xmean_ott = Xmean\n",
    "\n",
    "        if f < f_ott:\n",
    "            \n",
    "            U_ott = U\n",
    "            f_ott = f\n",
    "            Xmean_ott = Xmean\n",
    "\n",
    "    # calculate cost\n",
    "    cost = costf(X, Xmean_ott, U_ott)\n",
    "    print('Done')\n",
    "    return round(pd.DataFrame(U_ott), 4), f_ott, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kluster = kmeans_wrong(dataS, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our objective function has value: ', kluster[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function in the case of incorrect initialization of the algorithm has a greater value than our optimal solution (about 30 more!).\n",
    "So we can say that K-means is conditioned by the choice of initial centroids."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
